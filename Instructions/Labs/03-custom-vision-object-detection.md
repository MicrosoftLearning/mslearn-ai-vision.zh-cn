---
lab:
  title: 使用 Azure AI 自定义视觉检测图像中的对象
---

# 使用 Azure AI 自定义视觉检测图像中的对象

在此练习中，你将使用自定义视觉服务来训练*对象检测*模型，该模型可检测并找到图像中的三种水果（苹果、香蕉和橙子）。

## 创建自定义视觉资源

如果 Azure 订阅中已有用于训练和预测的“**自定义视觉**”资源，则可以在此练习中使用它们或某个现有的多服务帐户。 如果没有，请按照以下说明来创建自定义视觉资源。

> **备注**：如果使用多服务帐户，则训练和预测的密钥和终结点将相同。

1. 在新的浏览器标签页中，打开 Azure 门户 (`https://portal.azure.com`)，然后使用与 Azure 订阅关联的 Microsoft 帐户登录。
1. 选择 **&#65291;创建资源**按钮，搜索*自定义视觉*，并使用以下设置创建一个**自定义视觉**资源：
    - **创建选项**：共同点
    - **订阅**：*Azure 订阅*
    - **资源组**：*选择或创建一个资源组（如果使用受限制的订阅，你可能无权创建新的资源组 - 请使用提供的资源组）*
    - **区域**：*选择任何可用区域*
    - **名称**：*输入唯一名称*
    - **训练定价层**：F0
    - **预测定价层**：F0

    > **注意**：如果在你的订阅中已有 F0 自定义视觉服务，此处请选择**S0**。

1. 等待资源创建完成，然后查看部署详细信息，并注意两个自定义视觉资源是否已预配。一个资源用于训练，另一个用于预测（通过 **-Prediction** 后缀可判断出来）。 可以导航到你在其中创建了这些资源的资源组，然后查看这些资源。

> **重要说明**：每个资源都有自己的*终结点*和*密钥*，用于管理来自代码的访问。 若要训练图像分类模型，代码必须使用*训练*资源（及其终结点和密钥）；若要使用经过训练的模型来预测图像类别，代码必须使用*预测*资源（及其终结点和密钥）。

## 克隆本课程的存储库

你将在 Azure 门户中使用 Cloud Shell 开发代码。 你的应用的代码文件已在 GitHub 存储库中提供。

> **提示**：如果最近克隆了 mslearn-ai-vision**** 存储库，则可以跳过此任务。 否则，请按照以下步骤将其克隆到开发环境中。

1. 在 Azure 门户中，使用页面顶部搜索栏右侧的 **[\>_]** 按钮，在 Azure 门户中创建新的 Cloud Shell，选择 ***PowerShell*** 环境。 Cloud Shell 在 Azure 门户底部的窗格中提供命令行接口。

    > **备注**：如果以前创建了使用 *Bash* 环境的 Cloud Shell，请将其切换到 ***PowerShell***。

1. 在 Cloud Shell 工具栏的“**设置**”菜单中，选择“**转到经典版本**”（这是使用代码编辑器所必需的）。

    > **提示**：将命令粘贴到 cloudshell 中时，输出可能会占用大量屏幕缓冲区。 可以通过输入 `cls` 命令来清除屏幕，以便更轻松地专注于每项任务。

1. 在 PowerShell 窗格中，输入以下命令以克隆包含此练习的 GitHub 存储库：

    ```
    rm -r mslearn-ai-vision -f
    git clone https://github.com/microsoftlearning/mslearn-ai-vision mslearn-ai-vision
    ```

1. 克隆存储库后，导航到包含应用程序代码文件的文件夹：  

    ```
   cd mslearn-ai-vision/Labfiles/03-object-detection
    ```

## 创建自定义视觉项目

若要训练对象检测模型，需要基于训练资源创建自定义视觉项目。 为此，你将使用自定义视觉门户。

1. 在新的浏览器选项卡中，打开自定义视觉门户 (`https://customvision.ai`)，然后使用与 Azure 订阅关联的 Microsoft 帐户登录。
1. 创建一个具有以下设置的新项目：
    - **名称**：检测水果
    - **说明**：针对水果的对象检测。
    - **资源**：*先前创建的自定义视觉资源*
    - **项目类型**：对象检测
    - **域**：常规
1. 等待项目创建并在浏览器中打开。

## 添加图像并进行标记

若要训练对象检测模型，需要上传包含希望模型识别的类的图像，并标记这些图像以指示每个对象实例的边界框。

1. 从 `https://github.com/MicrosoftLearning/mslearn-ai-vision/raw/main/Labfiles/03-object-detection/training-images.zip` 中下载训练图像并解压缩 zip 文件夹以查看其内容。 此文件夹包含水果图像。
1. 在自定义视觉门户中的物体检测项目中，选择**添加图像**并上传提取的文件夹中的所有图像。
1. 上传图像后，选择第一个图像将其打开。
1. 将鼠标悬停在图像中的任意对象上，直到自动检测到的区域如下图所示。 然后选择对象，并根据需要调整区域大小以将其环绕。

    ![对象的默认区域](../media/object-region.jpg)

    或者，只需在对象周围拖动以创建区域。

1. 当区域环绕对象时，使用相应的对象类型（*苹果*、*香蕉*或*橘子*）添加新标记，如下所示：

    ![图像中的已标记对象](../media/object-tag.jpg)

1. 选择并标记图像中的各个对象，从而根据需要调整区域大小并添加新标记。

    ![图像中的两个已标记对象](../media/object-tags.jpg)

1. 使用右侧的 **>** 链接转到下一个图像，并标记其对象。 然后，继续处理整个图像集合，标记每个苹果、香蕉和橘子。

1. 标记完最后一个图像后，请关闭“**图像详细信息**”编辑器。 在“**训练图像**”页的“**标记**”下，选择“**已标记**”以查看所有标记的图像：

![项目中的已标记图像](../media/tagged-images.jpg)

## 使用训练 API 上传图像

可以使用“自定义视觉”门户中的 UI 对图像进行标记，但许多 AI 开发团队会使用其他工具来生成包含有关图像中的标记和对象区域信息的文件。 在此类情况下，可以使用自定义视觉训练 API 将带标记的图像上传到项目。

> **注意**：在此练习中，可以选择在 **C#** 或 **Python** SDK 中使用 API。 在下面的步骤中，请执行适用于你的语言首选项的操作。

1. 单击自定义视觉门户中**训练图像**页面右上方的*设置*(&#9881;) 图标，查看项目设置。
1. 在**常规**（左侧）下，注意唯一标识该项目的**项目 ID**。
1. 在右侧的**资源**下，可看到显示了密钥和终结点。 这些是*训练*资源的详细信息（还可通过在 Azure 门户中查看资源来获取这些信息）。
1. 返回 Azure 门户，根据语言首选项运行命令 `cd C-Sharp/train-detector` 或 `cd Python/train-detector`。
1. 通过运行适用于你的语言首选项的命令，安装自定义视觉训练包：

    **C#**

    ```
   dotnet add package Microsoft.Azure.CognitiveServices.Vision.CustomVision.Training --version 2.0.0
    ```

    **Python**

    ```
   pip install azure-cognitiveservices-vision-customvision==3.1.1
    ```

1. 使用 `ls` 命令可以查看 train-detector **** 文件夹的内容。 请注意，其中包含用于配置设置的文件：

    - **C#** ：appsettings.json
    - **Python**：.env

1. 输入以下命令以编辑已提供的配置文件：

    **C#**

    ```
   code appsettings.json
    ```

    **Python**

    ```
   code .env
    ```

    该文件已在代码编辑器中打开。

1. 在代码文件中，更新其包含的配置值，以反映自定义视觉训练资源的终结点和身份验证密钥，以及先前创建的物体检测项目的项目 ID。**********
1. 替换占位符后，在代码编辑器中使用 **CTRL+S** 命令或 ** 右键单击 > 保存** 保存更改，然后使用 **CTRL+Q** 命令或 ** 右键单击 > 退出** 关闭代码编辑器，同时保持 Cloud Shell 命令行打开。
1. 运行 `code tagged-images.json` 以打开文件，并检查其中包含的 JSON。 JSON 定义了一个图像列表，每个图像包含一个或多个带标记的区域。 每个带标记的区域均包括标记名称、顶部和左侧坐标，以及含带标记对象的边界框的宽度和高度维度。

    > **注意**：此文件中的坐标和维度表示在图像上的相对位置。 例如，*高度*值 0.7 表示框的高度是图像高度的 70%。 某些标记工具会生成其他格式的文件，其中坐标和维度值体现为像素、英寸或其他度量单位。

1. 请注意，**train-detector** 文件夹中包含子文件夹，其中存储了 JSON 文件中引用的图像文件。

1. 请注意，**train-detector** 文件夹中包含客户端应用程序的代码文件：

    - **C#** ：Program.cs
    - **Python**：train-detector.py

    打开代码文件并查看其中包含的代码，并注意以下详细信息：
    - 已导入你安装的包中的命名空间
    - **Main** 函数检索配置设置，并使用密钥和终结点来创建经过身份验证的 **CustomVisionTrainingClient**，然后将其与**项目** ID 结合使用以创建对项目的项目引用。
    - **Upload_Images** 函数从 JSON 文件提取带标记的区域信息，并按照该信息创建一批具有区域的图像，然后将其上传到项目。

1. 运行以下命令以运行程序：
    
    **C#**
    
    ```
   dotnet run
    ```
    
    **Python**
    
    ```
   python train-detector.py
    ```
    
1. 等待程序结束。 然后返回到浏览器，并在自定义视觉门户中查看项目的**训练图像**页面（如有必要，请刷新浏览器）。
1. 验证某些带标记的新图像是否已添加到项目中。

## 训练和测试模型

现在你已标记项目中的图像，即可训练模型。

1. 在自定义视觉项目中，单击**训练**以使用已标记的图像训练对象检测模型。 选择**快速训练**选项。
1. 等待训练完成（可能需要 10 分钟左右），然后检查*精度*、*召回*率和 *mAP* 性能指标 - 这些指标用于衡量分类模型的预测准确度，且应该都很高。
1. 在页面的右上角，单击**快速测试**，然后在**图像 URL**框中输入 `https://aka.ms/apple-orange` 并查看已生成的预测。 然后关闭**快速测试**窗口。

## 发布对象检测模型

现在即可发布经过训练的模型，以便在客户端应用程序中使用。

1. 在自定义视觉门户的**性能**页面上，单击 **&#128504; 发布**以使用以下设置发布经过训练的模型 ：
    - **模型名称**：fruit-detector
    - **预测资源**：*先前创建的以**Prediction**结尾的预测资源（<u>不是</u>训练资源）*。
1. 在**项目设置**页面的左上角，单击*项目库*(&#128065;) 图标以返回到自定义视觉门户主页，此时其中列出了你的项目。
1. 在自定义视觉门户主页的右上角，单击*设置*(&#9881;) 图标以查看自定义视觉服务的设置。 然后，在**资源**下查找以-Prediction结尾的*预测*资源（<u>不是</u>训练资源），以确定其**密钥**和**终结点**值（也可以通过在 Azure 门户中查看资源来获取这些信息）。

## 使用客户端应用程序中的图像分类器

现在，你已经发布了图像分类模型，接下来，可在客户端应用程序中使用。 同样，可以选择使用 **C#** 或 **Python**。

1. 在 Azure 门户中，运行命令 `cd ../test-detector` 以导航到 test-detector**** 文件夹。
1. 输入以下 SDK 特定的命令，安装自定义视觉预测包：

    **C#**

    ```
   dotnet add package Microsoft.Azure.CognitiveServices.Vision.CustomVision.Prediction --version 2.0.0
    ```

    **Python**

    ```
   pip install azure-cognitiveservices-vision-customvision==3.1.1
    ```

> **注意**：Python SDK 包包括训练和预测包，并且可能已安装完毕。

1. 打开客户端应用程序的配置文件（对于 C#，是 *appsettings.json*；对于 Python，则是 *.env*），并更新其包含的配置值，以反映自定义视觉*预测*资源的终结点和密钥、物体检测项目的项目 ID，以及发布的模型的名称（应为 *fruit-detector*）。 保存更改并关闭该文件。
1. 打开客户端应用程序的代码文件（对于 C#，是 *Program.cs*；对于 Python，则是 *test-detector.py*），然后查看其包含的代码，并注意以下详细信息 ：
    - 已导入你安装的包中的命名空间
    - **Main** 函数检索配置设置，并使用密钥和终结点创建经过身份验证的 **CustomVisionPredictionClient**。
    - 预测客户端对象用于获取 **produce.jpg** 图像的对象检测预测，并指定请求中的项目 ID 和模型名称。 然后，预测的带标记的区域会绘制在图像上，并且结果将另存为 **output.jpg**。
1. 关闭代码编辑器，输入以下命令以运行程序：

    **C#**

    ```
   dotnet run
    ```

    **Python**

    ```
   python test-detector.py
    ```

1. 程序完成后，在 Cloud Shell 工具栏中，选择“上传/下载文件”，然后选择“下载”。******** 在“新建”对话框中，输入下列文件路径，然后选择“下载”：****

    **C#**
   
    ```
   mslearn-ai-vision/Labfiles/03-object-detection/C-Sharp/test-detector/output.jpg
    ```

    **Python**
   
    ```
   mslearn-ai-vision/Labfiles/03-object-detection/Python/test-detector/output.jpg
    ```

1. 查看生成的 output.jpg 文件以查看图像中检测到的物体。****

## 清理资源

如果不将本实验室创建的 Azure 资源用于其他培训模块，则可以删除这些资源以避免产生更多费用。

1. 打开 Azure 门户网站 `https://portal.azure.com`，在顶部搜索栏中搜索在本实验室中创建的资源。

1. 在资源页面上，选择**删除**，然后按照说明删除资源。 或者，也可以删除整个资源组，同时清理所有资源。
   
## 详细信息

若要详细了解自定义视觉服务中的对象检测，请参阅[自定义视觉文档](https://docs.microsoft.com/azure/cognitive-services/custom-vision-service/)。
